# ğŸ“¦ AI-Powered MCP Server (MessageMedia + OpenAI)

This project is a full-stack AI-native SMS assistant built around the Model Context Protocol (MCP). It integrates:

- âœ… GPT-4 function calling
- âœ… MessageMedia SMS API (send, receive, delivery reports)
- âœ… Express-based webhook + chat server
- âœ… `/context` endpoint for AI memory
- âœ… HTML UI, OpenAI router, and message log dashboard
- âœ… GitHub + Railway-compatible Docker deployment

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ index.js             # MCP API server (context, send, webhooks)
â”œâ”€â”€ openai-router.js     # GPT interface w/ function calling
â”œâ”€â”€ start-all.js         # Starts both servers (for Docker)
â”œâ”€â”€ webhook-log.json     # Logs delivery + reply events
â”œâ”€â”€ conversations/       # Per-user GPT conversation logs
â”œâ”€â”€ chat-ui.html         # Simple browser-based chatbot
â”œâ”€â”€ Dockerfile           # Deployment container
â”œâ”€â”€ .env                 # Environment variables (NOT committed)
```

---

## âš™ï¸ .env File Format

Create a `.env` file like this:

```
MESSAGE_API_KEY=your_api_key
MESSAGE_API_SECRET=your_secret
MESSAGE_BASE_URL=https://api.messagemedia.com
OPENAI_API_KEY=your_openai_key
MCP_SERVER_URL=http://localhost:3000
CHAT_PORT=4000
PORT=3000
API_TOKEN=your_protected_token
```

---

## ğŸ§ª Local Testing

Install dependencies:
```bash
npm install
```

Start servers locally:
```bash
node start-all.js
```

Visit:
- [http://localhost:3000/dashboard](http://localhost:3000/dashboard)
- [http://localhost:4000/chat](http://localhost:4000/chat)
- Open `chat-ui.html` in browser

---

## ğŸ³ Docker Deployment

### Build and run locally with Docker

```bash
docker build -t mcp-sms .
docker run -p 3000:3000 -p 4000:4000 --env-file .env mcp-sms
```

### Required Ports
- `3000` for MCP context + webhook server
- `4000` for GPT chat API

Make sure `.env` exists in the same directory.

---

## ğŸš€ Deployment to Railway

1. Push your code to GitHub
2. Visit [https://railway.app](https://railway.app)
3. Create a **new project** â†’ Deploy from GitHub
4. Railway will auto-detect the `Dockerfile`
5. Add all `.env` variables in the **Variables** tab
6. Deploy and monitor logs

---

## ğŸ” GPT Functions Supported

### 1. get_sms_context

> Ask: â€œWhatâ€™s the message history for +61412345678?â€

Returns:
- Summary of last replies + delivery reports
- Prompt-friendly context

### 2. send_sms

> Ask: â€œSend an SMS to +61412345678 saying: your order is ready.â€

Triggers:
- MessageMedia API via `/send`
- GPT reply in chat UI

---

## ğŸ” Security & Rate Limiting

- Requires `Authorization: Bearer <API_TOKEN>` on all routes
- Limited to **30 requests per minute per IP**

---

## ğŸ§  Future Ideas

- ğŸ” GPT auto-replies to incoming SMS via `/webhook/reply`
- ğŸ“¥ Redis cache layer for `/context`
- ğŸ”Œ LangChain tools support
- ğŸ§‘â€ğŸ’» Admin UI to view/send messages manually

---

## ğŸ‘¨â€ğŸ’» Author

Built by @larryfang with â¤ï¸